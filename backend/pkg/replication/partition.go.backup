package replication























































































































































































































































}	return nil	}		return p.Log.Close()	if p.Log != nil {		defer p.mu.Unlock()	p.mu.Lock()func (p *Partition) Close() error {// Close closes the partition}	return p.Log.Read(offset)		defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) Read(offset int64) (*log.Record, error) {// Read reads a record from the partition}	return offset, nil		p.updateHWM()	// Recalculate HWM (might not change if followers haven't caught up)		p.leo = p.Log.HighWaterMark()	// Update LEO		}		return 0, fmt.Errorf("append to log: %w", err)	if err != nil {	offset, err := p.Log.Append(key, value)		defer p.mu.Unlock()	p.mu.Lock()func (p *Partition) Append(key, value []byte) (int64, error) {// Append appends a record to the partition (leader only)}	p.hwm = minLEO		}		}			minLEO = followerLEO		if followerLEO < minLEO {		followerLEO := p.followerLEOs[replicaID]				}			continue		if replicaID == p.Leader {	for _, replicaID := range p.ISR {	// Check follower LEOs that are in ISR		minLEO := p.leo	// Leader's LEOfunc (p *Partition) updateHWM() {// Must be called with write lock held// HWM is the minimum LEO among all ISR replicas// updateHWM recalculates the high water mark}	p.ISR = newISR		}		}			newISR = append(newISR, replicaID)		if followerLEO >= p.hwm && lagTimeMs < p.replicaLagTimeMaxMs {		// 2. Last fetch was within replica.lag.time.max.ms		// 1. LEO >= HWM (caught up with committed data)		// Follower is in sync if:				lagTimeMs := now.Sub(lastFetch).Milliseconds()		lastFetch := p.lastFetchTime[replicaID]		followerLEO := p.followerLEOs[replicaID]		// Check if follower is in sync				}			continue		if replicaID == p.Leader {	for _, replicaID := range p.Replicas {		newISR := []int32{p.Leader} // Leader is always in ISR	now := time.Now()func (p *Partition) updateISR() {// Must be called with write lock held// updateISR updates the ISR based on follower LEOs and lag time}	p.updateHWM()	// Recalculate HWM		p.updateISR()	// Update ISR based on follower LEO		p.lastFetchTime[followerID] = time.Now()	p.followerLEOs[followerID] = leo		defer p.mu.Unlock()	p.mu.Lock()func (p *Partition) UpdateFollowerLEO(followerID int32, leo int64) {// This is called when the leader receives a fetch request from a follower// UpdateFollowerLEO updates the LEO for a follower replica}	return p.leo	defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) LogEndOffset() int64 {// LogEndOffset returns the current log end offset (LEO)}	return p.hwm	defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) HighWaterMark() int64 {// HighWaterMark returns the current high water mark}	return p.Leader	defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) GetLeader() int32 {// GetLeader returns the leader broker ID}	return replicas	copy(replicas, p.Replicas)	replicas := make([]int32, len(p.Replicas))	defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) GetReplicas() []int32 {// GetReplicas returns all replicas}	return isr	copy(isr, p.ISR)	isr := make([]int32, len(p.ISR))	defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) GetISR() []int32 {// GetISR returns the current ISR (In-Sync Replicas)}	return false	}		}			return true		if replicaID == brokerID {	for _, replicaID := range p.Replicas {		}		return false	if p.Leader == brokerID {		defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) IsFollower(brokerID int32) bool {// IsFollower returns true if this broker is a follower for this partition}	return p.Leader == brokerID	defer p.mu.RUnlock()	p.mu.RLock()func (p *Partition) IsLeader(brokerID int32) bool {// IsLeader returns true if this broker is the leader for this partition}	return p, nil	}		}			p.lastFetchTime[replicaID] = time.Now()			p.followerLEOs[replicaID] = 0		if replicaID != config.Leader {	for _, replicaID := range config.Replicas {	// Initialize follower LEOs	copy(p.ISR, config.Replicas)	// Initialize ISR with all replicas	}		replicaLagTimeMaxMs: config.ReplicaLagTimeMaxMs,		lastFetchTime:       make(map[int32]time.Time),		followerLEOs:        make(map[int32]int64),		leo:                 partitionLog.HighWaterMark(),		hwm:                 0,		Log:                 partitionLog,		ISR:                 make([]int32, len(config.Replicas)), // Initially all replicas are in ISR		Replicas:            config.Replicas,		Leader:              config.Leader,		PartitionID:         config.PartitionID,		TopicName:           config.TopicName,	p := &Partition{	}		return nil, fmt.Errorf("create log: %w", err)	if err != nil {	partitionLog, err := log.NewLog(config.LogConfig)	// Create the log	}		config.ReplicaLagTimeMaxMs = 10000 // Default 10 seconds	if config.ReplicaLagTimeMaxMs <= 0 {func NewPartition(config PartitionConfig) (*Partition, error) {// NewPartition creates a new partition with replication support}	ReplicaLagTimeMaxMs int64 // Default: 10000ms	LogConfig           log.LogConfig	Replicas            []int32	Leader              int32	PartitionID         int32	TopicName           stringtype PartitionConfig struct {// PartitionConfig defines configuration for a partition}	replicaLagTimeMaxMs int64 // Max lag time for ISR membership	// Configuration		lastFetchTime  map[int32]time.Time // Last fetch time from each follower	followerLEOs   map[int32]int64  // Follower broker ID -> LEO	leo            int64            // Log End Offset (for leader)	hwm            int64            // High Water Mark	// Replication state	mu          sync.RWMutex	Log         *log.Log	ISR         []int32 // In-Sync Replicas	Replicas    []int32 // All replica broker IDs (including leader)	Leader      int32   // Leader broker ID	PartitionID int32	TopicName   stringtype Partition struct {// Partition represents a partition with replication support)	"github.com/takhin-data/takhin/pkg/storage/log"	"time"	"sync"	"fmt"import (package replication// Copyright 2025 Takhin Data, Inc.